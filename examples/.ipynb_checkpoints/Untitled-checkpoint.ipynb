{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23acdef-e7f2-4a3b-853d-e9d2d78f59e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from netCDF4 import Dataset\n",
    "import joblib\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from pvlib.location import Location\n",
    "\n",
    "from pycaret.regression import *\n",
    "import joblib\n",
    "\n",
    "global _LATLON_DIR\n",
    "global _BOUNDARY \n",
    "\n",
    "_LATLON_DIR = '/mnt/sdb1/wscho/data_for_research/ICTgk2a/latlon/'\n",
    "_BOUNDARY = 250\n",
    "\n",
    "class GK2ABaseProcessor(object):\n",
    "   \n",
    "\n",
    "\n",
    "    def main():\n",
    "        \n",
    "        return None\n",
    "        return None\n",
    "        return None\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def resolution_from_filename(gk2a_filename):\n",
    "        re_result = gk2a_filename[-23:-16]\n",
    "        resolution_str = re_result[2:5]\n",
    "        return float(resolution_str)*0.1\n",
    "\n",
    "\n",
    "    def cut_with_latlon(\n",
    "        self,\n",
    "        array, \n",
    "        ullatitude, \n",
    "        ullongitude, \n",
    "        lrlatitude, \n",
    "        lrlongitude,\n",
    "        boundary = True,\n",
    "    ):\n",
    "        arr = np.array(array)\n",
    "        \n",
    "\n",
    "        (ulrow, ulcol) = self.rowcol_from_latlon(ullatitude, ullongitude) \n",
    "        (lrrow, lrcol) = self.rowcol_from_latlon(lrlatitude, lrlongitude) \n",
    "        \n",
    "        ulrow = int(np.floor(ulrow))\n",
    "        ulcol = int(np.floor(ulcol))\n",
    "        lrrow = int(np.ceil(lrrow))\n",
    "        lrcol = int(np.ceil(lrcol)) \n",
    "\n",
    "        if boundary:\n",
    "            ulrow  -=  _BOUNDARY\n",
    "            ulcol  -=  _BOUNDARY \n",
    "            lrrow  +=  _BOUNDARY \n",
    "            lrcol  +=  _BOUNDARY \n",
    "        \n",
    "        clip = np.zeros((self.index_max, self.index_max))\n",
    "        \n",
    "        if ( \n",
    "            (ulcol <= lrcol)\n",
    "            and (ulrow <= lrrow) \n",
    "            and (0 <= ulcol) \n",
    "            and (lrcol < self.index_max) \n",
    "            and (0 <= ulrow) \n",
    "            and (lrrow < self.index_max) \n",
    "           ): \n",
    "            clip = arr[ulrow:lrrow, ulcol:lrcol]\n",
    "            self.lat_clip = self.lat[ulrow:lrrow, ulcol:lrcol]\n",
    "            self.lon_clip = self.lon[ulrow:lrrow, ulcol:lrcol]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid arguments, check [(ulcol <= lrcol), (ulrow <= lrrow), \" +\\\n",
    "                \"(0 <= ulcol), (lrcol < index_max), (0 <= ulrow), (lrrow < index_max)]\"\n",
    "            )\n",
    "        return clip\n",
    "\n",
    "\n",
    "    def latlon_from_rowcol(self, idx_row, idx_col):\n",
    "        \"\"\" returns latitude and longitude from index of row and column of an array \"\"\"\n",
    "        nlat = self.lat[idx_row, idx_col] \n",
    "        nlon = self.lon[idx_row, idx_col] \n",
    "        \n",
    "        return (nlat, nlon)\n",
    "    \n",
    "\n",
    "    def rowcol_from_latlon(self, latitude, longitude): \n",
    "        \"\"\" returns index of row and column from given latitude and longitude \"\"\"\n",
    "        distance = (self.lat - latitude )**2 + (self.lon - longitude)**2\n",
    "        target_rc = np.where(distance == distance.min())\n",
    "        nrow = target_rc[0]\n",
    "        ncol = target_rc[1]\n",
    "        \n",
    "        return (nrow, ncol)\n",
    "\n",
    "\n",
    "    def get_gk2a_var(self,file_key,var_name,base_dir,str_time):\n",
    "\n",
    "        time_org     =  datetime.strptime(str_time, \"%Y-%m-%d %H:%M\")\n",
    "        time_data   = time_org - timedelta(hours=9)\n",
    "        \n",
    "        str_time_data  = time_data.strftime(\"%Y%m%d%H%M\")\n",
    "        \n",
    "        var_path    =  os.path.join(base_dir, str_time_data[:-4], 'LE2' , file_key.lower())\n",
    "        gk2a_data   =  glob.glob(os.path.join(var_path, f'*{str_time_data}*.nc'))[0]\n",
    "        print(f\"using data named \\n'{gk2a_data}' \\nfor time '{time_org}'\")\n",
    "\n",
    "        ds = Dataset(gk2a_data)\n",
    "        var = ds[var_name]\n",
    "\n",
    "        return var\n",
    "\n",
    "\n",
    "    def get_gk2a_var_set(self,file_key,var_name,gk2a_path,base_dir,str_time):\n",
    "\n",
    "        var_set = []\n",
    "\n",
    "        for dt in range(3):\n",
    "            cur_time = datetime.strptime(str_time, \"%Y-%m-%d %H:%M\")  -  timedelta(minutes=(20-10*dt))\n",
    "            cur_str_time = cur_time.strftime(\"%Y-%m-%d %H:%M\")\n",
    "            var_set.append(self.get_gk2a_var(file_key,var_name,base_dir,cur_str_time))\n",
    "\n",
    "        return var_set\n",
    "\n",
    "\n",
    "    def cloud_amount_preproc(self,cloud_amount,resize=(1000, 800), normalize=True):\n",
    "        cloud_amount[cloud_amount>1] = 0\n",
    "        if normalize:\n",
    "            cloud_amount = (cloud_amount - cloud_amount.min()) / (cloud_amount.max() - cloud_amount.min()) * 255\n",
    "        # resize image\n",
    "        img = Image.fromarray(cloud_amount.astype('uint8')).resize(resize[::-1])\n",
    "        gk2a_preproc = np.array(img)\n",
    "\n",
    "        return gk2a_preproc\n",
    "\n",
    "\n",
    "    def warp_flow(self, img, flow):\n",
    "        h, w = flow.shape[:2]\n",
    "        flow = -flow\n",
    "        flow[:,:,0] += np.arange(w)\n",
    "        flow[:,:,1] += np.arange(h)[:,np.newaxis]\n",
    "        res = cv2.remap(img, flow, None, cv2.INTER_CUBIC, borderMode=cv2.BORDER_DEFAULT)\n",
    "\n",
    "        return res\n",
    "\n",
    "\n",
    "    def cal_optical_flow(self,optical_flow, gk2a_preproc, ca_pred_2d_path, time_interval=15 , f_interval=120, l_interval=240):        \n",
    "        prev = gk2a_preproc[-1]\n",
    "        forwrd = gk2a_preproc[-2]\n",
    "        forwrd2 = gk2a_preproc[-3]\n",
    "\n",
    "        f_time = int(f_interval / time_interval)\n",
    "        l_time = int(l_interval / time_interval)\n",
    "\n",
    "        print(\"-=\"*20+'-\\n')\n",
    "        print(f'   First Prediction  : + {f_interval} minutes')\n",
    "        print(f'   Last  Prediction  : + {l_interval} minutes\\n')\n",
    "        print(\"-=\"*20+'-\\n')\n",
    "\n",
    "        if ((f_interval%time_interval)!=0)|((l_interval%time_interval)!=0):\n",
    "            raise ValueError(\n",
    "                \"Time interval needs to be a divisor of 'first prediction time and last prediction time'!\"\n",
    "            )\n",
    "        raw_prev = prev.copy()\n",
    "        bf_flow = optical_flow.calc(forwrd2, forwrd, None)\n",
    "        flow = optical_flow.calc(forwrd, prev, None)\n",
    "        acc = time_interval/10*(flow - bf_flow)\n",
    "        flow *= time_interval/10\n",
    "\n",
    "        raw_predict = []\n",
    "\n",
    "        for i in range(l_time):\n",
    "\n",
    "            print(f'   Calculating + {15*(i+1)} minutes Cloud Amount\\n')\n",
    "\n",
    "            raw_prev = self.warp_flow(raw_prev, flow) \n",
    "            flow += acc\n",
    "            if i >= (f_time-1):\n",
    "                raw_predict.append(raw_prev)\n",
    "        \n",
    "        predict = [\n",
    "            (gaussian_filter(\n",
    "            cur_predict, sigma=1,truncate = 4)[_BOUNDARY:-_BOUNDARY,_BOUNDARY:-_BOUNDARY]/255).round(2)\n",
    "            for cur_predict in raw_predict\n",
    "            ]\n",
    "        with open(ca_pred_2d_path, 'wb') as f:\n",
    "            pickle.dump(predict, f)\n",
    "\n",
    "    #method : ['OBS', 'Plant']\n",
    "    def pick_var_target(self,ca_path,ca_pred_2d_path,meta_path,\n",
    "        str_time, time_interval=15 , f_interval=120, l_interval=240):\n",
    "\n",
    "        lat_clip = self.lat_clip\n",
    "        lon_clip = self.lon_clip\n",
    "\n",
    "        stn_meta = pd.read_pickle(meta_path)\n",
    "\n",
    "        with open(ca_pred_2d_path, 'rb') as f:\n",
    "            ca_pred_2d = pickle.load(fi)\n",
    "\n",
    "        ca_pred = pd.DataFrame({'stn_id':[],\n",
    "                               'stn_name' :[],\n",
    "                               'dt' : []})\n",
    "\n",
    "        stn_meta['nrow'] = np.NaN\n",
    "        stn_meta['ncol'] = np.NaN\n",
    "\n",
    "\n",
    "        for m,cur_result in enumerate(ca_pred_2d):\n",
    "\n",
    "            ca_pred[f'cloud_index_+{15*(m+8)}min'] = 0.00 \n",
    "\n",
    "            for i, cur_row in stn_meta.iterrows():\n",
    "                distance = (lat_clip - cur_row['latitude'] )**2 + (lon_clip - cur_row['longitude'])**2\n",
    "                target_rc = np.where(distance == distance.min())\n",
    "\n",
    "                stn_meta['nrow'][i]= target_rc[0][0]\n",
    "                stn_meta['ncol'][i] = target_rc[1][0]\n",
    "\n",
    "                cur_time = pd.to_datetime(str_time, format='%Y-%m-%d %H:%M').tz_localize('Asia/Seoul')+ timedelta(minutes=f_interval + m*time_interval)\n",
    "                cur_ca  = cur_result[target_rc[0][0],target_rc[1][0]]\n",
    "                ca_pred = ca_pred.append(pd.DataFrame([[cur_row.stn_id, cur_row.stn_nm,cur_time,cur_ca]], columns=['stn_id', 'stn_nm','dt','ca']))\n",
    "        ca_pred = ca_pred.set_idnex('dt')\n",
    "        stn_meta[['nrow','ncol']] = stn_meta[['nrow','ncol']].astype(int)\n",
    "\n",
    "        ca_pred.to_pickle(ca_path)\n",
    "        stn_meta.to_pickle(meta_path)\n",
    "\n",
    "\n",
    "    #method : ['OBS', 'gk2a']\n",
    "    def cal_clear_sky(cs_path, meta_path, input_path, method = 'OBS'):\n",
    "\n",
    "        ca_col = []\n",
    "        if method=='OBS':\n",
    "            ca_col = 'cloud_index'\n",
    "\n",
    "        cs_data = pd.DataFrame()\n",
    "        input_data = pd.read_pickle(input_path)\n",
    "        meta_data = pd.read_pickle(meta_path)\n",
    "\n",
    "        for i, row in meta_data.iterrows():\n",
    "            stn_nm = row.stn_nm\n",
    "            print(stn_nm)\n",
    "\n",
    "            cur_input = input_data[['stn_id','stn_nm', 'true_ghi','latitude','longitude','altitude']+ ca_col][input_data.stn_nm == stn_nm]\n",
    "            lat, lon, alt = row.latitude, row.longitude, row.altitude\n",
    "            stn_loc = Location(lat, lon, altitude=alt, tz='Asia/Seoul')\n",
    "\n",
    "            solpos = stn_loc.get_solarposition(cur_input.index)\n",
    "            cs_irrads = stn_loc.get_clearsky(cur_input.index, solar_position=solpos)\n",
    "            cs_irrads.columns = [f'cs_{c}' for c in cs_irrads.columns]\n",
    "            cur_input = cur_input.join(solpos).join(cs_irrads)\n",
    "            cs_data = cs_data.append(cur_input)\n",
    "\n",
    "            # if method == 'OBS' run following process\n",
    "            # replace irradiance of np.nan value measured at hour H with 0\n",
    "            # if solar elevation for that time is less than 0\n",
    "            # calculates gradient of the cumulative irradiance function\n",
    "            # to get the instantaneous power output for each hour\n",
    "            # convert MJ -> Watt (just converting unit in this step)\n",
    "\n",
    "        cs_data.to_pickel(cs_path)\n",
    "\n",
    "\n",
    "    def preproc_asos_ghi(cs_path, meta_path, input_path):\n",
    "\n",
    "        asos_data = pd.read_pickle(cs_path)\n",
    "        meta_data = pd.read_pickle(meta_path)\n",
    "        asos_data_preproc = pd.DataFrame()\n",
    "\n",
    "        for i, row in meta_path.iterrows():\n",
    "            cur_asos = asos_data[asos_data.stn_nm == row.stn_nm]\n",
    "            cur_asos.loc[cur_asos.true_ghi.isnull() & (cur_asos.elevation < 0), 'true_ghi'] = 0.\n",
    "            cur_asos = cur_asos.sort_index()\n",
    "            ghi_cumsum = cur_asos.groupby(cur_asos.index.date)['true_ghi'].cumsum()\n",
    "            \n",
    "            ghi_deriv = ghi_cumsum.groupby(ghi_cumsum.index.date).\\\n",
    "                                            apply(lambda x: pd.DataFrame(np.gradient(x, x.index.hour,edge_order = 1), index=x.index) if len(x)>1 else pd.DataFrame([np.NaN], index=x.index))[0].rename('true_ghi_corrected')\n",
    "            \n",
    "            cur_asos = cur_asos.join(ghi_deriv)\n",
    "            cur_asos['true_ghi_corrected'] *= 277.7777\n",
    "            asos_data_preproc = asos_data_preproc.append(cur_asos)\n",
    "\n",
    "            asos_data_preproc.rename(columns = {'true_ghi' : 'true_ghi_cum',\n",
    "                                        'true_ghi_corrected' : 'true_ghi',\n",
    "                                        }, inplace = True)\n",
    "            asos_data_preproc.to_pickle(cs_path)\n",
    "\n",
    "\n",
    "    def prepare_features(cs_path, ca_pred_path, cs_data):\n",
    "        gk2a_data = pd.read_pickle(ca_pred_path)\n",
    "        cs_data = pd.read_pickle(cs_path)\n",
    "\n",
    "        input_data = gk2a_data.reset_index().merge(cs_data, on = ['dt','stn_id']).set_index('dt')\n",
    "        input_data['Cloud_OD'] = (input_data.true_ghi-input_data.cs_dhi)/(input_data.cs_dni)\n",
    "        input_data = input_data[(input_data['Cloud_OD']>=0)&(input_data['Cloud_OD']<=1)]\n",
    "        input_data['cloud_index'] *= 0.1\n",
    "        input_data['cloud_index'] = input_data.cloud_index+0.05\n",
    "        input_data['cloud_index'] = input_data['cloud_index'].clip(0,1)\n",
    "        input_data['cal_Cloud_OD'] = ((1-input_data.cloud_index)/((1/np.cos(np.pi/180*input_data.zenith)) - (input_data.cloud_index))).clip(0,1)\n",
    "        \n",
    "        return input_data\n",
    "\n",
    "\n",
    "    def fitting_ghi_ref(self,input_data, model_path, result_path, model_name = 'lightgbm',trs_switch = True):\n",
    "\n",
    "        target_col = 'Cloud_OD'\n",
    "        ghi_test_set = []\n",
    "        errors = np.zeros(11)\n",
    "        ghi_OBS = pd.DataFrame()\n",
    "\n",
    "        for z,cur_cloud_OD in enumerate(np.arange(0,1.01,0.1)):\n",
    "            \n",
    "            print('='*20)\n",
    "            print(f'cloud index      =      {cur_cloud_OD}')\n",
    "\n",
    "            cur_cloud_OD +=0.05\n",
    "            cur_cloud_OD = cur_cloud_OD.clip(0,1)\n",
    "\n",
    "            if trs_switch :  trs  =  0.025\n",
    "            else      :  trs  =  100000\n",
    "            \n",
    "            tmp_ghi = input_data[input_data.zenith<90].copy()\n",
    "            tmp_ghi = tmp_ghi[abs(tmp_ghi.cloud_index - cal_cloud)<trs]\n",
    "            tmp_ghi.cal_Cloud_OD = tmp_ghi.cal_Cloud_OD.round(4)\n",
    "            tmp_ghi = tmp_ghi.dropna()\n",
    "            \n",
    "            ghi_OBS = ghi_OBS.append(tmp_ghi[['name','stn_id','latitude','longitude','true_ghi']])\n",
    "            \n",
    "            #==========================================================================================================================================\n",
    "            \n",
    "            model_col = ['azimuth', 'zenith','cs_ghi','cs_dni', 'cs_dhi', 'cloud_index','latitude','longitude', 'altitude', 'cal_Cloud_OD', 'Cloud_OD']\n",
    "            ghi_test = [model_col]\n",
    "            ghi_test_set.append(ghi_test)\n",
    "            \n",
    "            ghi_model = setup(session_id=1234, train_size=0.8, data = ghi_to, target = target_col, normalize=True, transformation=True, use_gpu=False, silent =True)\n",
    "            ghi_model_res = compare_models(n_select=1,sort = 'MAE', include=[model_name])\n",
    "\n",
    "            tuned_model = tune_model(ghi_model_res)\n",
    "            final_model = finalize_model(tuned_model)\n",
    "            \n",
    "            save_model(final_model, model_path)\n",
    "            \n",
    "            result = predict_model(final_model, data=ghi_test)\n",
    "\n",
    "            y = result.Label\n",
    "            x = result.Cloud_OD\n",
    "            errors[z] = np.mean(abs(y-x))\n",
    "\n",
    "            result.to_pickle(result_path)\n",
    "            self.model = result\n",
    "\n",
    "            print(errors[z])\n",
    "\n",
    "            return result\n",
    "\n",
    "\n",
    "\n",
    "class GK2AFDProcessor(GK2ABaseProcessor):\n",
    "    \n",
    "    DEG2RAD = 3.14159265358979 / 180.0 \n",
    "    \n",
    "    def __init__(self, resolution=None, gk2a_filename=None, size=None):\n",
    "\n",
    "        if resolution:\n",
    "            self.resolution = resolution    \n",
    "        elif gk2a_filename:\n",
    "            self.resolution = self.resolution_from_filename(gk2a_filename)\n",
    "        elif size:\n",
    "            self.resolution = self.resolution_from_size(size)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Should input one of resolution and gk2a_filename\"\n",
    "            )\n",
    "        if (self.resolution == 0.5):\n",
    "            self.COFF = 11000.5\n",
    "            self.CFAC = 8.170135561335742e7\n",
    "            self.LOFF = 11000.5\n",
    "            self.LFAC = 8.170135561335742e7\n",
    "            self.index_max = 22000\n",
    "        elif (self.resolution == 1.0):\n",
    "            self.COFF = 5500.5\n",
    "            self.CFAC = 4.0850677806678705e7\n",
    "            self.LOFF = 5500.5\n",
    "            self.LFAC = 4.0850677806678705e7\n",
    "            self.index_max = 11000\n",
    "        elif (self.resolution == 2.0):\n",
    "            self.COFF = 2750.5\n",
    "            self.CFAC = 2.0425338903339352e7\n",
    "            self.LOFF = 2750.5\n",
    "            self.LFAC = 2.0425338903339352e7\n",
    "            self.index_max = 5500\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid resolution, which should be one of [0.5, 1.0, 2.0]\"\n",
    "            )\n",
    "        self.sub_lon = 128.2 \n",
    "        self.sub_lon = self.sub_lon * self.DEG2RAD\n",
    "\n",
    "        latlons = Dataset(glob.glob(os.path.join(_LATLON_DIR, '*fd*.nc'))[0])\n",
    "        self.lat = latlons['lat'][:]\n",
    "        self.lon = latlons['lon'][:]\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def resolution_from_size(size):\n",
    "        #\"\"\" if you do not know resolution, use size of full disk data to find resolution\"\"\"\n",
    "        if size == 22000:\n",
    "            return np.float(0.5)\n",
    "        if size == 11000:\n",
    "            return np.float(1.0)\n",
    "        if size == 5500:\n",
    "            return np.float(2.0)\n",
    "        \n",
    "            \n",
    "        def latlon_from_rowcol_fd_old(self, idx_row, idx_col):\n",
    "            \"\"\" returns latitude and longitude from index of row and column of an array \"\"\"\n",
    "            x = self.DEG2RAD * ( (idx_col - self.COFF)*2**16 / self.CFAC )\n",
    "            y = self.DEG2RAD * ( (idx_row - self.LOFF)*2**16 / self.LFAC )\n",
    "            Sd = np.sqrt( (42164.0*np.cos(x)*np.cos(y))**2 - (np.cos(y)**2 + 1.006739501*np.sin(y)**2)*1737122264)\n",
    "            Sn = (42164.0*np.cos(x)*np.cos(y)-Sd) / (np.cos(y)**2 + 1.006739501*np.sin(y)**2)\n",
    "            S1 = 42164.0 - ( Sn * np.cos(x) * np.cos(y) )\n",
    "            S2 = Sn * ( np.sin(x) * np.cos(y) )\n",
    "            S3 = -Sn * np.sin(y)\n",
    "            Sxy = np.sqrt( ((S1*S1)+(S2*S2)) )\n",
    "\n",
    "            nlon = (np.arctan(S2/S1)+self.sub_lon)/self.DEG2RAD \n",
    "            nlat = np.arctan( ( 1.006739501 *S3)/Sxy)/self.DEG2RAD\n",
    "            \n",
    "            return (nlat, nlon)\n",
    "        \n",
    "        def rowcol_from_latlon_fd_old(self, latitude, longitude): \n",
    "        #\"\"\" returns index of row and column from given latitude and longitude \"\"\"\n",
    "            latitude = latitude * self.DEG2RAD \n",
    "            longitude = longitude * self.DEG2RAD\n",
    "            c_lat = np.arctan(0.993305616*np.tan(latitude))\n",
    "            RL = 6356.7523 / np.sqrt( 1.0 - 0.00669438444 * np.cos(c_lat)**2.0 ) \n",
    "            R1 = 42164.0 - RL * np.cos(c_lat) * np.cos(longitude - self.sub_lon)\n",
    "            R2 = -RL * np.cos(c_lat) *np.sin(longitude - self.sub_lon)\n",
    "            R3 = RL* np.sin(c_lat)\n",
    "            Rn = np.sqrt(R1**2.0 + R2**2.0 + R3**2.0 )\n",
    "            x = np.arctan(-R2 / R1) / self.DEG2RAD \n",
    "            y = np.arcsin(-R3 / Rn) / self.DEG2RAD \n",
    "\n",
    "            ncol = self.COFF + (x * 2.0**(-16) * self.CFAC) \n",
    "            nrow = self.LOFF + (y * 2.0**(-16) * self.LFAC)\n",
    "\n",
    "            return (nrow, ncol)\n",
    "\n",
    "\n",
    "\n",
    "class GK2AEAProcessor(GK2ABaseProcessor):\n",
    "\n",
    "    DEG2RAD = 3.14159265358979 / 180.0\n",
    "\n",
    "    def __init__(self, resolution=None, gk2a_filename=None, size=None):\n",
    "        \n",
    "        if resolution:\n",
    "            self.resolution = resolution    \n",
    "        elif gk2a_filename:\n",
    "            self.resolution = self.resolution_from_filename(gk2a_filename)\n",
    "        elif size:\n",
    "            self.resolution = self.resolution_from_size(size)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Should input one of resolution and gk2a_filename\"\n",
    "            )\n",
    "            \n",
    "        if (self.resolution == 0.5):\n",
    "            self.index_max = 12000\n",
    "        elif (self.resolution == 1.0):\n",
    "            self.index_max = 6000\n",
    "        elif (self.resolution == 2.0):\n",
    "            self.index_max = 3000\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid resolution, which should be one of [0.5, 1.0, 2.0]\"\n",
    "            )\n",
    "            \n",
    "        latlons = Dataset(glob.glob(os.path.join(_LATLON_DIR, '*ea*.nc'))[0])\n",
    "        self.lat = latlons['lat'][:]\n",
    "        self.lon = latlons['lon'][:]\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def resolution_from_size(size):\n",
    "        \"\"\" if you do not know resolution, use size of full disk data to find resolution\"\"\"\n",
    "        if size == 12000:\n",
    "            return np.float(0.5)\n",
    "        if size == 6000:\n",
    "            return np.float(1.0)\n",
    "        if size == 3000:\n",
    "            return np.float(2.0)\n",
    "\n",
    "\n",
    "\n",
    "class GK2AKOProcessor(GK2ABaseProcessor):\n",
    "    \n",
    "    _LATLON_DIR = '/mnt/sdb1/wscho/data_for_research/ICTgk2a/latlon/'\n",
    "    DEG2RAD = 3.14159265358979 / 180.0 \n",
    "    \n",
    "    def __init__(self, resolution=None, gk2a_filename=None, size=None):\n",
    "        \n",
    "        if resolution:\n",
    "            self.resolution = resolution    \n",
    "        elif gk2a_filename:\n",
    "            self.resolution = self.resolution_from_filename(gk2a_filename)\n",
    "        elif size:\n",
    "            self.resolution = self.resolution_from_size(size)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Should input one of resolution and gk2a_filename\"\n",
    "            )\n",
    "            \n",
    "        if (self.resolution == 0.5):\n",
    "            self.index_max = 2400\n",
    "        elif (self.resolution == 1.0):\n",
    "            self.index_max = 1200\n",
    "        elif (self.resolution == 2.0):\n",
    "            self.index_max = 900\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid resolution, which should be one of [0.5, 1.0, 2.0]\"\n",
    "            )\n",
    "            \n",
    "        latlons = Dataset(glob.glob(os.path.join(_LATLON_DIR, '*ko*.nc'))[0])\n",
    "        self.lat = latlons['lat'][:]\n",
    "        self.lon = latlons['lon'][:]\n",
    "    \n",
    "    @staticmethod\n",
    "    def resolution_from_size(size):\n",
    "        \"\"\" if you do not know resolution, use size of full disk data to find resolution\"\"\"\n",
    "        if size == 2400:\n",
    "            return np.float(0.5)\n",
    "        if size == 1800:\n",
    "            return np.float(1.0)\n",
    "        if size == 900:\n",
    "            return np.float(2.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICTWork",
   "language": "python",
   "name": "ictwork"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
